{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import deepos\n",
    "import deepops as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give your tensor a cool name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Tensors\n",
    "a = dp.Tensor([1.0]*100000, name = \"leo\")\n",
    "b = dp.Tensor([2.0]*100000, name = \"brad pitt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leo\n",
      "brad pitt\n"
     ]
    }
   ],
   "source": [
    "print(a.name)\n",
    "print(b.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add: dp.Tensor shape: (100000,), numpy: ([3. 3. 3. ... 3. 3. 3.], dtype=float32), cuda device: cpu  Mul: dp.Tensor shape: (100000,), numpy: ([2. 2. 2. ... 2. 2. 2.], dtype=float32), cuda device: cpu \n"
     ]
    }
   ],
   "source": [
    "# Tensor Operations on CPU\n",
    "print(\"Add:\", a+b, \"Mul:\", a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dp.Tensor shape: (100000,), numpy: ([1. 1. 1. ... 1. 1. 1.], dtype=float32), cuda device: cpu "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default Device is cpu\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dp.Tensor shape: (100000,), numpy: (<pycuda._driver.DeviceAllocation object at 0x7f855c6655d0>, dtype=float32), cuda device: gpu "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# throw these Tensors in our precious GPU\n",
    "a.device('gpu') # i.e gpu:0\n",
    "b.device('gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add them on GPU\n",
    "addition = a.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dp.Tensor shape: (100000,), numpy: (<pycuda._driver.DeviceAllocation object at 0x7f85292b7120>, dtype=float32), cuda device: gpu "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the Addition\n",
    "addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dp.Tensor shape: (100000,), numpy: (<pycuda._driver.DeviceAllocation object at 0x7f85292b7e40>, dtype=float32), cuda device: gpu "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adds beautifully with itself!\n",
    "a.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp.Tensor shape: (100000,), numpy: (<pycuda._driver.DeviceAllocation object at 0x7f8529306ad0>, dtype=float32), cuda device: gpu \n"
     ]
    }
   ],
   "source": [
    "print(a + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp.Tensor shape: (100000,), numpy: (<pycuda._driver.DeviceAllocation object at 0x7f85292b7df0>, dtype=float32), cuda device: gpu \n"
     ]
    }
   ],
   "source": [
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dp.Tensor shape: (100000,), numpy: (<pycuda._driver.DeviceAllocation object at 0x7f85292b7170>, dtype=float32), cuda device: gpu '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackPropogration is real now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = dp.Tensor\n",
    "a1 = Tensor([1.0, 3.0, 1.0])\n",
    "b1 = Tensor([7.0, 3.0, 5.0])\n",
    "\n",
    "a2 = Tensor([4.0, 3.0, 1.0])\n",
    "a3 = Tensor([3.0, 3.0, 1.0])\n",
    "a4 = Tensor([7.0, 1.0, 6.0])\n",
    "b2 = Tensor([1.0, 21.0, 12.0])\n",
    "\n",
    "c = a1 * b1 + a3\n",
    "d = a2 * b2 + a4\n",
    "out = c * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate gradients in style!!\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output gradients\n",
    "out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients for dp.Tensor shape: (3,), numpy: ([1. 3. 1.], dtype=float32), cuda device: cpu  tensor is : [ 77. 192.  90.]\n",
      "Gradients for dp.Tensor shape: (3,), numpy: ([4. 3. 1.], dtype=float32), cuda device: cpu  tensor is : [ 10. 252.  72.]\n",
      "Gradients for dp.Tensor shape: (3,), numpy: ([3. 3. 1.], dtype=float32), cuda device: cpu  tensor is : [11. 64. 18.]\n",
      "Gradients for dp.Tensor shape: (3,), numpy: ([7. 1. 6.], dtype=float32), cuda device: cpu  tensor is : [10. 12.  6.]\n",
      "Gradients for dp.Tensor shape: (3,), numpy: ([7. 3. 5.], dtype=float32), cuda device: cpu  tensor is : [ 11. 192.  18.]\n",
      "Gradients for dp.Tensor shape: (3,), numpy: ([ 1. 21. 12.], dtype=float32), cuda device: cpu  tensor is : [40. 36.  6.]\n",
      "Gradients for dp.Tensor shape: (3,), numpy: ([10. 12.  6.], dtype=float32), cuda device: cpu  tensor is : [11. 64. 18.]\n",
      "Gradients for dp.Tensor shape: (3,), numpy: ([11. 64. 18.], dtype=float32), cuda device: cpu  tensor is : [10. 12.  6.]\n"
     ]
    }
   ],
   "source": [
    "# Gradients\n",
    "_ = [print(f\"Gradients for {tensor} tensor is : {tensor.grad}\") for tensor in [a1,a2,a3,a4,b1,b2,c,d]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
